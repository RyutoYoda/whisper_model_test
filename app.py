import base64
import os
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
st.set_page_config(
    page_title="VoiceCat",
    page_icon="ğŸˆ"
)

st.title("VoiceCatğŸˆ")

with st.expander("VoiceCatã«ã¤ã„ã¦"):
    st.write("""
        VoiceCatğŸˆã¯ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã€ãã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡ç¤ºã«å¿œã˜ã¦å‡¦ç†ã€è§£æã™ã‚‹ã‚¢ãƒ—ãƒªã§ã™ã€‚
        
        **ä½¿ã„æ–¹:**
        1. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚(https://platform.openai.com/api-keys)
        2. ã€Œå‡¦ç†å†…å®¹ã®å…¥åŠ›ã€ã«å‡¦ç†ã¨ã—ã¦ã«è¡Œã„ãŸã„æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¾ã™ï¼ˆä¾‹: ã€Œã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€ï¼‰ã€‚
        3. ã€ŒéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ãŸã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚
        4. ã€ŒéŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã¾ã™ã€‚
        5. æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚ŒãŸå¾Œã€ã€Œå‡¦ç†ã‚’é–‹å§‹ã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€æ–‡å­—èµ·ã“ã—ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®è§£æã‚’è¡Œã„ã¾ã™ã€‚
        6. å‡¦ç†çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦å‡¦ç†çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚
    """)

# APIã‚­ãƒ¼ã®å–å¾—
api_key = st.sidebar.text_input("OpenAI API Key", type="password", value=os.getenv("OPENAI_API_KEY") or "")

if not api_key:
    st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=api_key)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…¥åŠ›
sidebar_prompt = st.sidebar.text_input("å‡¦ç†å†…å®¹ã®å…¥åŠ›ï¼ˆä¾‹ï¼šã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã—ã¦ãã ã•ã„ï¼‰")

# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
audio_file = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["m4a", "mp3", "webm", "mp4", "mpga", "wav"])

if audio_file is not None:
    st.audio(audio_file, format="audio/wav")

    if st.button("éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã™ã‚‹"):
        with st.spinner("éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­ã§ã™..."):
            transcript = client.audio.transcriptions.create(
                model="whisper-1", file=audio_file, response_format="text"
            )
        st.success("éŸ³å£°æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        st.session_state.transcript = transcript  # æ–‡å­—èµ·ã“ã—çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚‹å ´åˆã«è¡¨ç¤º
if 'transcript' in st.session_state and st.session_state.transcript is not None:
    st.write(st.session_state.transcript)

# ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ãƒœã‚¿ãƒ³
if st.button("å‡¦ç†ã‚’é–‹å§‹ã™ã‚‹"):
    if 'transcript' in st.session_state and st.session_state.transcript is not None:
        prompt = sidebar_prompt + st.session_state.transcript  # promptã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ–‡å­—èµ·ã“ã—çµæœã‚’ä½¿ç”¨

        with st.spinner("å‡¦ç†ã‚’å®Ÿè¡Œä¸­ã§ã™..."):
            response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ãå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„"},
                        {"role": "user", "content": prompt}
                    ]
                )
            summary_result = response.choices[0].message.content

            # è¦ç´„çµæœã‚’è¡¨ç¤º
            #st.write("è¦ç´„å‰ã®ãƒ†ã‚­ã‚¹ãƒˆ:")
            #st.write(st.session_state.transcript)  # æ–‡å­—èµ·ã“ã—çµæœã‚’å†è¡¨ç¤º
            st.write("å‡¦ç†çµæœ:")
            st.write(summary_result)

            # å¿œç­”ã‚’ãƒã‚¤ãƒˆã«å¤‰æ›ã—ã€ãã‚Œã‚’ base64 ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹
            response_encoded = base64.b64encode(summary_result.encode()).decode()

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ
            st.markdown(
                f'<a href="data:file/txt;base64,{response_encoded}" download="summary_result.txt">å‡¦ç†çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>',
                unsafe_allow_html=True,
            )
    else:
        st.warning("éŸ³å£°æ–‡å­—èµ·ã“ã—ã®çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

            
